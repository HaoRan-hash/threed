{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from ignite.metrics import Accuracy\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 数据部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelNet40(Dataset):\n",
    "    def __init__(self, root, split='train', npoints=1024):\n",
    "        super(ModelNet40, self).__init__()\n",
    "        self.npoints = npoints\n",
    "        self.class_to_idx = {}\n",
    "\n",
    "        with open(os.path.join(root, 'modelnet40_shape_names.txt'), 'r') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                line = line.strip()\n",
    "                self.class_to_idx[line] = i\n",
    "\n",
    "        self.file_paths = []\n",
    "        self.labels = []\n",
    "        with open(os.path.join(root, 'modelnet40_'+split+'.txt'), 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                temp = line.split('_')\n",
    "                self.file_paths.append(os.path.join(root, '_'.join(temp[0:-1]), line + '.txt'))\n",
    "                self.labels.append(self.class_to_idx['_'.join(temp[0:-1])])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def pcd_norm(self, points):\n",
    "        mean = points.mean(axis=0)\n",
    "        points = points - mean\n",
    "        max_dis = (np.sqrt((np.square(points)).sum(axis=1))).max()\n",
    "        points = points / max_dis\n",
    "\n",
    "        return points\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file = self.file_paths[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        points = np.genfromtxt(file, delimiter=',', dtype=np.float32)\n",
    "\n",
    "        points = points[0:self.npoints, :]\n",
    "\n",
    "        points[:, 0:3] = self.pcd_norm(points[:, 0:3])\n",
    "\n",
    "        return points, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ModelNet40('modelnet40_normal_resampled', split='train')\n",
    "test_dataset = ModelNet40('modelnet40_normal_resampled', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'airplane': 0, 'bathtub': 1, 'bed': 2, 'bench': 3, 'bookshelf': 4, 'bottle': 5, 'bowl': 6, 'car': 7, 'chair': 8, 'cone': 9, 'cup': 10, 'curtain': 11, 'desk': 12, 'door': 13, 'dresser': 14, 'flower_pot': 15, 'glass_box': 16, 'guitar': 17, 'keyboard': 18, 'lamp': 19, 'laptop': 20, 'mantel': 21, 'monitor': 22, 'night_stand': 23, 'person': 24, 'piano': 25, 'plant': 26, 'radio': 27, 'range_hood': 28, 'sink': 29, 'sofa': 30, 'stairs': 31, 'stool': 32, 'table': 33, 'tent': 34, 'toilet': 35, 'tv_stand': 36, 'vase': 37, 'wardrobe': 38, 'xbox': 39}\n",
      "9843\n",
      "2468\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.class_to_idx)\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd, gt = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.6534191e-09 -3.8970029e-08 -2.0793777e-08 -2.2611087e-02\n",
      "  6.2716450e-03  6.5562748e-03]\n",
      "[0.18740387 0.9741179  0.99170816 ... 0.42549008 0.17417295 0.16141398]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 检验norm是否正确\n",
    "mean = pcd.mean(axis=0)\n",
    "print(mean)\n",
    "dis = np.sqrt((np.square(pcd[:, 0:3])).sum(axis=1))\n",
    "print(dis)\n",
    "max_dis = dis.max()\n",
    "print(max_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'int'>\n",
      "(1024, 6) float32\n"
     ]
    }
   ],
   "source": [
    "print(type(pcd), type(gt))\n",
    "print(pcd.shape, pcd.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=24, shuffle=True, num_workers=8)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=24, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcds, labels = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 1024, 6]) torch.float32\n",
      "torch.Size([24]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(pcds.shape, pcds.dtype)\n",
    "print(labels.shape, labels.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 模型部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointSetAbstractionLayer(nn.Module):\n",
    "    def __init__(self, nsamples, radius, k, in_channels, mlp_units, is_group_all=False):\n",
    "        super(PointSetAbstractionLayer, self).__init__()\n",
    "        self.nsamples = nsamples\n",
    "        self.radius = radius\n",
    "        self.k = k\n",
    "        self.is_group_all = is_group_all\n",
    "        \n",
    "        mlp = [nn.Conv2d(in_channels, mlp_units[0], kernel_size=1),\n",
    "                    nn.BatchNorm2d(mlp_units[0]),\n",
    "                    nn.ReLU(inplace=True)]\n",
    "        for i in range(len(mlp_units) - 1):\n",
    "            mlp += [nn.Conv2d(mlp_units[i], mlp_units[i + 1], kernel_size=1),\n",
    "                    nn.BatchNorm2d(mlp_units[i + 1]),\n",
    "                    nn.ReLU(inplace=True)]\n",
    "\n",
    "        self.mlp = nn.Sequential(*mlp)\n",
    "    \n",
    "    def fps(self, points):\n",
    "        \"\"\"\n",
    "        points.shape = (b, n, 3)\n",
    "        return indices.shape = (b, self.nsamples)\n",
    "        \"\"\"\n",
    "        b, n, _ = points.shape\n",
    "        device = points.device\n",
    "        dis = torch.ones((b, n), device=device) * 1e10\n",
    "        indices = torch.zeros((b, self.nsamples), device=device, dtype=torch.long)\n",
    "\n",
    "        for i in range(1, self.nsamples):\n",
    "            cur_index = indices[:, i - 1].view(b, 1, 1).repeat(1, 1, 3)\n",
    "            cur_point = points.gather(1, cur_index)\n",
    "\n",
    "            temp = (points - cur_point).square().sum(axis=2)\n",
    "            mask = (temp < dis)\n",
    "            dis[mask] = temp[mask]\n",
    "\n",
    "            index = dis.argmax(dim=1)\n",
    "            dis[list(range(b)), index] = 0\n",
    "            indices[:, i] = index\n",
    "        return indices\n",
    "\n",
    "\n",
    "    def index_points(self, points, indices):\n",
    "        \"\"\"\n",
    "        points.shape = (b, n, c)\n",
    "        indices.shape = (b, self.nsamples) or (b, self.nsamples, k)\n",
    "        return res.shape = (b, self.nsamples, c) or (b, self.nsamples, k, c)\n",
    "        \"\"\"\n",
    "        _, _, c = points.shape\n",
    "        if len(indices.shape) == 2:\n",
    "            indices = indices.unsqueeze(dim=2).expand(-1, -1, c)\n",
    "            res = points.gather(dim=1, index=indices)\n",
    "        elif len(indices.shape) == 3:\n",
    "            indices = indices.unsqueeze(dim=3).expand(-1, -1, -1, c)\n",
    "            points = points.unsqueeze(dim=1).expand(-1, self.nsamples, -1, -1)\n",
    "            res = points.gather(dim=2, index=indices)\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def index_points_2(self, points, idx):\n",
    "        device = points.device\n",
    "        B = points.shape[0]\n",
    "        view_shape = list(idx.shape)\n",
    "        view_shape[1:] = [1] * (len(view_shape) - 1)\n",
    "        repeat_shape = list(idx.shape)\n",
    "        repeat_shape[0] = 1\n",
    "        batch_indices = torch.arange(B, dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)\n",
    "        new_points = points[batch_indices, idx, :]\n",
    "        return new_points\n",
    "\n",
    "    def get_square_distance(self, points_1, points_2):\n",
    "        \"\"\"\n",
    "        points_1.shape = (b, n, 3)\n",
    "        points_2.shape = (b, self.nsamples, 3)\n",
    "        return res.shape = (b, self.nsampels, n)\n",
    "        \"\"\"\n",
    "        b, n, _ = points_1.shape\n",
    "\n",
    "        points_1 =points_1.view(b, 1, n, 3)\n",
    "        points_2 =points_2.view(b, self.nsamples, 1, 3)   \n",
    "        res = (points_2 -points_1).square().sum(dim=-1)   # 内部会自动做广播处理\n",
    "\n",
    "        return res\n",
    "    \n",
    "    def group(self, points, features, centroids, distance):\n",
    "        \"\"\"\n",
    "        points.shape = (b, n, 3)\n",
    "        features.shape = (b, n, c)\n",
    "        centroids.shape = (b, self.nsamples, 3)\n",
    "        distance.shape = (b, self.nsampels, n)\n",
    "        return res.shape = (b, self.nsamples, k, 3+c)\n",
    "        \"\"\"\n",
    "        sorted_distance, indices = distance.sort(dim=-1)\n",
    "        sorted_distance = sorted_distance[:, :, 0:self.k]\n",
    "        indices = indices[:, :, 0:self.k]\n",
    "\n",
    "        temp = indices[:, :, 0].unsqueeze(dim=2).repeat(1, 1, self.k)\n",
    "        mask = (sorted_distance > self.radius ** 2)\n",
    "        indices[mask] = temp[mask]\n",
    "\n",
    "        group_points = self.index_points(points, indices)\n",
    "        group_point_features = self.index_points(features, indices)\n",
    "\n",
    "        # group_points = self.index_points_2(points, indices)\n",
    "        # group_point_features = self.index_points_2(features, indices)\n",
    "\n",
    "        temp = centroids.unsqueeze(dim=2)\n",
    "        group_points = group_points - temp   # 要的是相对坐标\n",
    "\n",
    "        res = torch.cat((group_points, group_point_features), dim=-1)\n",
    "        return res\n",
    "\n",
    "    def group_all(self, points, features):\n",
    "        \"\"\"\n",
    "        points.shape = (b, n, 3)\n",
    "        features.shape = (b, n, c)\n",
    "        return centroids.shape = (b, 3, 1)\n",
    "        return group_features.shape = (b, c', 1)\n",
    "        \"\"\"\n",
    "        b, n, _ = points.shape\n",
    "        device = points.device\n",
    "        indices = torch.randint(0, n, (b, 1), device=device)\n",
    "\n",
    "        centroids = self.index_points(points, indices)\n",
    "        # centroids = self.index_points_2(points, indices)\n",
    "\n",
    "        indices = torch.arange(0, n, device=device)\n",
    "        indices = indices.view(1, 1, n).repeat(b, 1, 1)\n",
    "        group_points = self.index_points(points, indices)\n",
    "        group_features = self.index_points(features, indices)\n",
    "\n",
    "        # group_points = self.index_points_2(points, indices)\n",
    "        # group_features = self.index_points_2(features, indices)\n",
    "\n",
    "        temp = centroids.unsqueeze(dim=2)\n",
    "        group_points = group_points - temp\n",
    "\n",
    "        group_features = torch.cat((group_points, group_features), dim=-1)\n",
    "        group_features = group_features.permute(0, 3, 2, 1)\n",
    "\n",
    "        group_features = self.mlp(group_features)\n",
    "        group_features, _ = group_features.max(dim=2)\n",
    "\n",
    "        centroids = centroids.permute(0, 2, 1)\n",
    "\n",
    "        return centroids, group_features\n",
    "\n",
    "    \n",
    "    def forward(self, points, features):\n",
    "        \"\"\"\n",
    "        points.shape = (b, 3, n)   坐标信息\n",
    "        features.shape = (b, c, n)   特征信息\n",
    "        return centroids.shape = (b, 3, self.nsamples)\n",
    "        return group_features.shape = (b, c', self.nsamples)\n",
    "        \"\"\"\n",
    "        points = points.permute(0, 2, 1)\n",
    "        features = features.permute(0, 2, 1)\n",
    "        if self.is_group_all:\n",
    "            centroids, group_features = self.group_all(points, features)\n",
    "            return centroids, group_features\n",
    "\n",
    "        fps_indices = self.fps(points)\n",
    "\n",
    "        centroids = self.index_points(points, fps_indices)\n",
    "        # centroids = self.index_points_2(points, fps_indices)\n",
    "\n",
    "        square_distance = self.get_square_distance(points, centroids)\n",
    "\n",
    "        group_features = self.group(points, features, centroids, square_distance)\n",
    "        group_features = group_features.permute(0, 3, 2, 1)\n",
    "\n",
    "        group_features = self.mlp(group_features)\n",
    "        group_features, _ = group_features.max(dim=2)\n",
    "\n",
    "        centroids = centroids.permute(0, 2, 1)\n",
    "\n",
    "        return centroids, group_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNetPlusPlus(nn.Module):\n",
    "    def __init__(self, class_num):\n",
    "        super(PointNetPlusPlus, self).__init__()\n",
    "        self.sa1 = PointSetAbstractionLayer(512, 0.2, 32, 6+3, [64, 64, 128])\n",
    "        self.sa2 = PointSetAbstractionLayer(128, 0.4, 64, 128+3, [128, 128, 256])\n",
    "        self.sa3 = PointSetAbstractionLayer(1, None, None, 256+3, [256, 512, 1024], True)\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(1024, 512),\n",
    "                                nn.BatchNorm1d(512),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Dropout(0.4),\n",
    "                                nn.Linear(512, 256),\n",
    "                                nn.BatchNorm1d(256),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Dropout(0.4),\n",
    "                                nn.Linear(256, class_num))\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x.shape = (b, n, 3+c)\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 2, 1)\n",
    "        points = x[:, 0:3, :]\n",
    "        features = x\n",
    "\n",
    "        points_layer1, features_layer1 = self.sa1(points, features)\n",
    "        points_layer2, features_layer2 = self.sa2(points_layer1, features_layer1)\n",
    "        points_layer3, features_layer3 = self.sa3(points_layer2, features_layer2)\n",
    "\n",
    "        final_features = features_layer3.squeeze()\n",
    "\n",
    "        y = self.mlp(final_features)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, metric_fn, optimizer, device, cur_epoch, total_epoch, show_gap, interval):\n",
    "    model.train()\n",
    "    if cur_epoch % show_gap == 0:\n",
    "        pbar = tqdm(dataloader, desc=f'Epoch {cur_epoch}/{total_epoch}', unit='batch')\n",
    "    else:\n",
    "        pbar = dataloader\n",
    "\n",
    "    for i, (x, y) in enumerate(pbar):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        metric_fn.reset()\n",
    "        metric_fn.update((y_pred, y))\n",
    "        acc = metric_fn.compute()\n",
    "\n",
    "        if cur_epoch % show_gap == 0 and i % interval == 0:\n",
    "            pbar.set_postfix_str(f'loss={loss:.4f}, acc={acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "best_epoch = 0\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, metric_fn, device, cur_epoch, path, show_gap):\n",
    "    model.eval()\n",
    "    steps = len(dataloader)\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss += loss_fn(y_pred, y)\n",
    "\n",
    "            metric_fn.reset()\n",
    "            metric_fn.update((y_pred, y))\n",
    "            acc += metric_fn.compute()\n",
    "    loss = loss / steps\n",
    "    acc = acc / steps\n",
    "\n",
    "    global best_acc, best_epoch\n",
    "    if acc >= best_acc:\n",
    "        torch.save(model.state_dict(), path)\n",
    "        best_acc = acc\n",
    "        best_epoch = cur_epoch\n",
    "\n",
    "    if cur_epoch % show_gap == 0:\n",
    "        print(f'test_loss={loss:.4f}, test_acc={acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "\n",
    "pointnet = PointNetPlusPlus(40).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "metric_fn = Accuracy(device=device)\n",
    "optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647467f6a0674c82914d7b92af775092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0/200:   0%|          | 0/411 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/mchen/chenhr/pointnet++_cls.ipynb Cell 19'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000018vscode-remote?line=2'>3</a>\u001b[0m save_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpointnet++_cls.pth\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000018vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000018vscode-remote?line=4'>5</a>\u001b[0m     train_loop(train_dataloader, pointnet, loss_fn, metric_fn, optimizer, device, i, epochs, show_gap, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000018vscode-remote?line=5'>6</a>\u001b[0m     test_loop(test_dataloader, pointnet, loss_fn, metric_fn, device, i, save_path, show_gap)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000018vscode-remote?line=6'>7</a>\u001b[0m     lr_scheduler\u001b[39m.\u001b[39mstep()\n",
      "\u001b[1;32m/home/mchen/chenhr/pointnet++_cls.ipynb Cell 15'\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, metric_fn, optimizer, device, cur_epoch, total_epoch, show_gap, interval)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000014vscode-remote?line=9'>10</a>\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000014vscode-remote?line=10'>11</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000014vscode-remote?line=11'>12</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000014vscode-remote?line=12'>13</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(y_pred, y)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000014vscode-remote?line=13'>14</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch1.10/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/pytorch1.10/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/pytorch1.10/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/pytorch1.10/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/pytorch1.10/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/anaconda3/envs/pytorch1.10/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/pytorch1.10/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/pytorch1.10/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/mchen/chenhr/pointnet++_cls.ipynb Cell 14'\u001b[0m in \u001b[0;36mPointNetPlusPlus.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000013vscode-remote?line=23'>24</a>\u001b[0m points \u001b[39m=\u001b[39m x[:, \u001b[39m0\u001b[39m:\u001b[39m3\u001b[39m, :]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000013vscode-remote?line=24'>25</a>\u001b[0m features \u001b[39m=\u001b[39m x\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000013vscode-remote?line=26'>27</a>\u001b[0m points_layer1, features_layer1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msa1(points, features)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000013vscode-remote?line=27'>28</a>\u001b[0m points_layer2, features_layer2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msa2(points_layer1, features_layer1)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000013vscode-remote?line=28'>29</a>\u001b[0m points_layer3, features_layer3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msa3(points_layer2, features_layer2)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch1.10/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/pytorch1.10/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/pytorch1.10/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/pytorch1.10/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/pytorch1.10/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/anaconda3/envs/pytorch1.10/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/pytorch1.10/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/pytorch1.10/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/mchen/chenhr/pointnet++_cls.ipynb Cell 13'\u001b[0m in \u001b[0;36mPointSetAbstractionLayer.forward\u001b[0;34m(self, points, features)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000012vscode-remote?line=158'>159</a>\u001b[0m     centroids, group_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroup_all(points, features)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000012vscode-remote?line=159'>160</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m centroids, group_features\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000012vscode-remote?line=161'>162</a>\u001b[0m fps_indices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfps(points)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000012vscode-remote?line=163'>164</a>\u001b[0m centroids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_points(points, fps_indices)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000012vscode-remote?line=164'>165</a>\u001b[0m \u001b[39m# centroids = self.index_points_2(points, fps_indices)\u001b[39;00m\n",
      "\u001b[1;32m/home/mchen/chenhr/pointnet++_cls.ipynb Cell 13'\u001b[0m in \u001b[0;36mPointSetAbstractionLayer.fps\u001b[0;34m(self, points)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000012vscode-remote?line=29'>30</a>\u001b[0m cur_index \u001b[39m=\u001b[39m indices[:, i \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mview(b, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mrepeat(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000012vscode-remote?line=30'>31</a>\u001b[0m cur_point \u001b[39m=\u001b[39m points\u001b[39m.\u001b[39mgather(\u001b[39m1\u001b[39m, cur_index)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000012vscode-remote?line=32'>33</a>\u001b[0m temp \u001b[39m=\u001b[39m (points \u001b[39m-\u001b[39;49m cur_point)\u001b[39m.\u001b[39;49msquare()\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000012vscode-remote?line=33'>34</a>\u001b[0m mask \u001b[39m=\u001b[39m (temp \u001b[39m<\u001b[39m dis)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmengchen/home/mchen/chenhr/pointnet%2B%2B_cls.ipynb#ch0000012vscode-remote?line=34'>35</a>\u001b[0m dis[mask] \u001b[39m=\u001b[39m temp[mask]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "show_gap = 1\n",
    "save_path = 'pointnet++_cls.pth'\n",
    "for i in range(epochs):\n",
    "    train_loop(train_dataloader, pointnet, loss_fn, metric_fn, optimizer, device, i, epochs, show_gap, 1)\n",
    "    test_loop(test_dataloader, pointnet, loss_fn, metric_fn, device, i, save_path, show_gap)\n",
    "    lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_acc, best_epoch)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "10e950a2d02279e5457baa6feefd0499ef078fb1b2957debc5d17c17df001893"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch1.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
