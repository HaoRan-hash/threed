{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import points_query\n",
    "import phf_cuda\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S3dis(Dataset):\n",
    "    def __init__(self, root, split, loop, npoints=24000, voxel_size=0.04, test_area=5, transforms=None):\n",
    "        super(S3dis, self).__init__()\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.loop = loop\n",
    "        self.npoints = npoints\n",
    "        self.voxel_size = voxel_size\n",
    "        self.transforms = transforms\n",
    "        self.idx_to_class = {0: 'ceiling', 1: 'floor', 2: 'wall', 3: 'beam', 4: 'column', \n",
    "                5: 'window', 6: 'door', 7: 'table', 8: 'chair', 9: 'sofa', 10: 'bookcase', 11: 'board', 12: 'clutter'}\n",
    "        \n",
    "        room_list = os.listdir(root)\n",
    "        if split == 'train':\n",
    "            self.room_list = list(filter(lambda x : f'Area_{test_area}' not in x, room_list))\n",
    "        else:\n",
    "            self.room_list = list(filter(lambda x : f'Area_{test_area}' in x, room_list))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.room_list) * self.loop\n",
    "\n",
    "    def voxel_grid_sampling(self, pos):\n",
    "        \"\"\"\n",
    "        pos.shape = (n, 3)\n",
    "        \"\"\"\n",
    "        voxel_indices = np.floor(pos / self.voxel_size).astype(np.int64)\n",
    "        voxel_max = voxel_indices.max(axis=0)\n",
    "        \n",
    "        temp = np.ones_like(voxel_max)\n",
    "        temp[1] = voxel_max[0]\n",
    "        temp[2] = voxel_max[0] * voxel_max[1]\n",
    "        \n",
    "        voxel_hash = (voxel_indices * temp).sum(axis=-1)\n",
    "        sort_idx = voxel_hash.argsort()\n",
    "        \n",
    "        _, counts = np.unique(voxel_hash, return_counts=True)\n",
    "        if self.split == 'test':   # test时需要的东西和train，val时不同\n",
    "            return sort_idx, counts\n",
    "        \n",
    "        idx_select = np.cumsum(np.insert(counts, 0, 0)[0:-1]) + np.random.randint(0, counts.max(), counts.size) % counts\n",
    "        return sort_idx[idx_select]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        room = os.path.join(self.root, self.room_list[index % len(self.room_list)])\n",
    "        points = np.load(room)\n",
    "        \n",
    "        # 大家都这样做\n",
    "        points[:, 0:3] = points[:, 0:3] - np.min(points[:, 0:3], axis=0)\n",
    "        \n",
    "        if self.split == 'test':\n",
    "            sort_idx, counts = self.voxel_grid_sampling(points[:, 0:3])\n",
    "            pos, x, y = points[:, 0:3], points[:, 3:-1], points[:, -1]\n",
    "            pos, x, y = pos.astype(np.float32), x.astype(np.float32), y.astype(np.int64)\n",
    "            return pos, x, y, sort_idx, counts\n",
    "        \n",
    "        # train, val的流程\n",
    "        sample_indices = self.voxel_grid_sampling(points[:, 0:3])\n",
    "        # 再随机采固定个点\n",
    "        if self.split == 'train':\n",
    "            sample_indices = np.random.choice(sample_indices, (self.npoints, ))\n",
    "        pos, x, y = points[sample_indices, 0:3], points[sample_indices, 3:-1], points[sample_indices, -1]\n",
    "        if self.transforms:\n",
    "            pos, x = self.transforms(pos, x)\n",
    "        \n",
    "        pos, x, y = pos.astype(np.float32), x.astype(np.float32), y.astype(np.int64)\n",
    "        return pos, x, y\n",
    "\n",
    "\n",
    "class Compose:\n",
    "    def __init__(self, transforms):\n",
    "        \"\"\"\n",
    "        transforms: List\n",
    "        \"\"\"\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, pos, x):\n",
    "        for transform in self.transforms:\n",
    "            pos, x = transform(pos, x)\n",
    "        return pos, x\n",
    "\n",
    "\n",
    "class PointCloudFloorCentering:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, pos, x):\n",
    "        pos = pos - pos.mean(axis=0, keepdims=True)\n",
    "        pos[:, 2] = pos[:, 2] - pos[:, 2].min()\n",
    "        \n",
    "        return pos, x\n",
    "\n",
    "\n",
    "class ColorNormalize:\n",
    "    def __init__(self, mean=[0.5136457, 0.49523646, 0.44921124], std=[0.18308958, 0.18415008, 0.19252081]):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    \n",
    "    def __call__(self, pos, x):\n",
    "        x = x / 255\n",
    "        x = (x - self.mean) / self.std\n",
    "        \n",
    "        return pos, x\n",
    "\n",
    "\n",
    "def index_points(points, indices):\n",
    "    \"\"\"\n",
    "    points.shape = (b, n, c)\n",
    "    indices.shape = (b, nsamples) or (b, nsamples, k)\n",
    "    return res.shape = (b, nsamples, c) or (b, nsamples, k, c)\n",
    "    \"\"\"\n",
    "    device = points.device\n",
    "    b = points.shape[0]\n",
    "\n",
    "    view_shape = list(indices.shape)\n",
    "    view_shape[1:] = [1] * (len(view_shape) - 1)\n",
    "    expand_shape = list(indices.shape)\n",
    "    expand_shape[0] = -1\n",
    "    batch_indices = torch.arange(b, device=device).view(view_shape).expand(expand_shape)\n",
    "    res = points[batch_indices, indices, :]\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def my_knn_query(k, query_pos, all_pos, all_x):\n",
    "    \"\"\"\n",
    "    query_pos.shape = (b, sample, 3)\n",
    "    all_pos.shape = (b, n, 3)\n",
    "    all_x.shape = (b, n, c)\n",
    "    return shape = (b, sample, k, 3), (b, sample, k, c), (b, sample, k)\n",
    "    \"\"\"\n",
    "    b, m, _ = query_pos.shape\n",
    "    device = query_pos.device\n",
    "    k_indices = torch.zeros((b, m, k), dtype=torch.long, device=device)\n",
    "    k_dis = torch.zeros((b, m, k), dtype=torch.float32, device=device)\n",
    "    \n",
    "    points_query.knn_query(k, all_pos, query_pos, k_indices, k_dis)\n",
    "    return index_points(all_pos, k_indices), index_points(all_x, k_indices), k_dis\n",
    "\n",
    "\n",
    "def my_ball_query(radius, k, query_pos, all_pos, all_x):\n",
    "    \"\"\"\n",
    "    query_pos.shape = (b, sample, 3)\n",
    "    all_pos.shape = (b, n, 3)\n",
    "    all_x.shape = (b, n, c)\n",
    "    return shape = (b, sample, k, 3), (b, sample, k, c), (b, sample, k)\n",
    "    \"\"\"\n",
    "    b, m, _ = query_pos.shape\n",
    "    device = query_pos.device\n",
    "    k_indices = torch.zeros((b, m, k), dtype=torch.long, device=device)\n",
    "    k_dis = torch.zeros((b, m, k), dtype=torch.float32, device=device)\n",
    "    \n",
    "    points_query.ball_query(k, radius, all_pos, query_pos, k_indices, k_dis)\n",
    "    return index_points(all_pos, k_indices), index_points(all_x, k_indices), k_dis\n",
    "\n",
    "\n",
    "def point_hist_feature(group_points, distance):\n",
    "    \"\"\"\n",
    "    group_points.shape = (b, n, k, 3)   相对坐标\n",
    "    distance,shape = (b, n, k)\n",
    "    return res.shape = (b, n, 8)\n",
    "    \"\"\"\n",
    "    b, n, k, _ = group_points.shape\n",
    "    device = group_points.device\n",
    "    masks = torch.zeros((b, n, k, 8), device=device, dtype=torch.float32)\n",
    "    \n",
    "    phf_cuda.phf(group_points, masks)\n",
    "    dist = distance.unsqueeze(dim=-1)\n",
    "\n",
    "    hist_features = (dist * masks).sum(dim=2)\n",
    "    return hist_features\n",
    "\n",
    "\n",
    "def get_normal(pos):\n",
    "    b, n, _ = pos.shape\n",
    "    pos = pos.to(device='cpu', dtype=torch.float64).numpy()\n",
    "    res = np.zeros((b, n, 3), dtype=np.float64)\n",
    "    \n",
    "    for i in range(b):\n",
    "        temp = pos[i]\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(temp)   # 必须是float64\n",
    "        # pcd.estimate_normals(o3d.geometry.KDTreeSearchParamRadius(0.2))\n",
    "        pcd.estimate_normals()\n",
    "        res[i] = pcd.normals\n",
    "    \n",
    "    res = torch.as_tensor(res.astype(np.float32))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_aug = Compose([PointCloudFloorCentering(),\n",
    "                            ColorNormalize()])\n",
    "val_dataset = S3dis('/home/lindi/chenhr/threed/data/processed_s3dis', split='val', loop=1, transforms=val_aug)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=8)\n",
    "\n",
    "val_iter = iter(val_dataloader)\n",
    "for i in range(6):\n",
    "    pos, x, y = next(val_iter)\n",
    "\n",
    "# 数据转移到gpu\n",
    "device = 'cuda:2'\n",
    "pos = pos.to(device=device)\n",
    "x = x.to(device=device)\n",
    "y = y.to(device=device)\n",
    "\n",
    "neigh_pos, _, dis = my_knn_query(64, pos, pos, x)\n",
    "neigh_pos = neigh_pos - pos.unsqueeze(dim=2)\n",
    "hist_features = point_hist_feature(neigh_pos[:, :, 1:, :], dis[:, :, 1:])   # hist_features.shape = (b, n, 8)\n",
    "\n",
    "# neigh_pos, _, _ = my_ball_query(0.1, 8, pos, pos, x)\n",
    "# centers = neigh_pos.mean(dim=2, keepdim=True)\n",
    "# neigh_pos = neigh_pos - centers\n",
    "# dis = (neigh_pos ** 2).sum(dim=-1)\n",
    "# hist_features = point_hist_feature(neigh_pos, dis)\n",
    "\n",
    "hist_features = hist_features[0].to('cpu').numpy()\n",
    "y = y[0].to('cpu').numpy()\n",
    "# tsne = TSNE(init='random', learning_rate='auto')\n",
    "# low_features = tsne.fit_transform(hist_features)\n",
    "# print(low_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = hist_features[y == 0].mean(axis=0)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = hist_features[y == 1].mean(axis=0)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_aug = Compose([PointCloudFloorCentering(),\n",
    "                            ColorNormalize()])\n",
    "val_dataset = S3dis('/home/lindi/chenhr/threed/data/processed_s3dis', split='val', loop=1, transforms=val_aug)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=8)\n",
    "\n",
    "val_iter = iter(val_dataloader)\n",
    "for i in range(6):\n",
    "    pos, x, y = next(val_iter)\n",
    "\n",
    "normal = get_normal(pos)\n",
    "print(normal.shape)\n",
    "y = y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(init='random', learning_rate='auto')\n",
    "low_features = tsne.fit_transform(normal[0])\n",
    "print(low_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_aug = Compose([PointCloudFloorCentering(),\n",
    "                            ColorNormalize()])\n",
    "val_dataset = S3dis('/home/lindi/chenhr/threed/data/processed_s3dis', split='val', loop=1, transforms=val_aug)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=8)\n",
    "\n",
    "val_iter = iter(val_dataloader)\n",
    "for i in range(5):\n",
    "    pos, x, y = next(val_iter)\n",
    "\n",
    "pos = pos[0].to(torch.float64).numpy()\n",
    "x = x[0].to(torch.float64).numpy()\n",
    "y = y[0].to(torch.float64).numpy()\n",
    "\n",
    "tsne = TSNE(init='random', learning_rate='auto')\n",
    "low_features = tsne.fit_transform(x)\n",
    "print(low_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (y == 0)\n",
    "plt.scatter(low_features[mask][:, 0], low_features[mask][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (y == 1)\n",
    "plt.scatter(low_features[mask][:, 0], low_features[mask][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (y == 2)\n",
    "plt.scatter(low_features[mask][:, 0], low_features[mask][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (y == 4)\n",
    "plt.scatter(low_features[mask][:, 0], low_features[mask][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (y == 5)\n",
    "plt.scatter(low_features[mask][:, 0], low_features[mask][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (y == 6)\n",
    "plt.scatter(low_features[mask][:, 0], low_features[mask][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (y == 7)\n",
    "plt.scatter(low_features[mask][:, 0], low_features[mask][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (y == 8)\n",
    "plt.scatter(low_features[mask][:, 0], low_features[mask][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (y == 9)\n",
    "plt.scatter(low_features[mask][:, 0], low_features[mask][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (y == 10)\n",
    "plt.scatter(low_features[mask][:, 0], low_features[mask][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (y == 11)\n",
    "plt.scatter(low_features[mask][:, 0], low_features[mask][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (y == 12)\n",
    "plt.scatter(low_features[mask][:, 0], low_features[mask][:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch1.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:18) \n[GCC 10.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "147477ce5941b7544d8fd876fb1d06933df4e9c43ffccfe86baaf7d8ac1055f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
